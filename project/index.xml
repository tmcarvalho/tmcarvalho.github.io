<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Tânia Carvalho</title>
    <link>https://tmcarvalho.github.io/project/</link>
      <atom:link href="https://tmcarvalho.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2021 Tânia Carvalho</copyright><lastBuildDate>Sat, 20 Jan 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://tmcarvalho.github.io/media/icon_hudd826bf8b7cdb19f447252b8976756b2_613384_512x512_fill_lanczos_center_3.png</url>
      <title>Projects</title>
      <link>https://tmcarvalho.github.io/project/</link>
    </image>
    
    <item>
      <title>ε-PrivateSMOTE</title>
      <link>https://tmcarvalho.github.io/project/privatesmote/</link>
      <pubDate>Sat, 20 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://tmcarvalho.github.io/project/privatesmote/</guid>
      <description>&lt;p&gt;ε-PrivateSMOTE is a technique designed for safeguarding against re-identification and linkage attacks, particularly addressing cases with a high re-identification risk. It generates synthetic data via noise-induced interpolation with differential privacy principles to obfuscate high-risk cases.
ε-PrivateSMOTE allows having new cases similar to the originals while preserving privacy and maximising predictive utility. Most importanly,
ε-PrivateSMOTE is a resource efficient and less time-consuming than conventional de-identification approaches such as deep learning and differential privacy-based solutions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hands-on data de-identification</title>
      <link>https://tmcarvalho.github.io/project/example/</link>
      <pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://tmcarvalho.github.io/project/example/</guid>
      <description>&lt;p&gt;Statistical Disclosure Control seeks to reduce the risk of confidential information
disclosure by de-identifying them. Such de-identification is guaranteed through privacy-preserving
techniques (PPTs). However, de-identified data usually results in loss of information, with a possible impact on data analysis precision and model predictive performance.
This course covers the de-identification process which aims to protect the individual’s privacy while maintaining the interpretability of the data (i.e., its usefulness). The program includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Introduction to Python&lt;/li&gt;
&lt;li&gt;Introduction to data privacy&lt;/li&gt;
&lt;li&gt;Predictive modeling&lt;/li&gt;
&lt;li&gt;Privacy-preserving techniques&lt;/li&gt;
&lt;li&gt;Training&lt;/li&gt;
&lt;li&gt;Current directions on data privacy&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
