[{"authors":null,"categories":null,"content":"I received my Master\u0026rsquo;s degree in Network and Information Systems Engineering from the Faculty of Sciences, University of Porto, in 2019. I am currently pursuing a Ph.D. in Computer Science at FCUP, with a dedicated research focus on \u0026ldquo;Automated Privacy-Preserving Strategies\u0026rdquo;.\nIn the context of machine learning and privacy, I have a particular interest in promoting the responsible and ethical use of data-driven technologies. My research focuses on secure data sharing using machine learning. Specifically, I\u0026rsquo;ve been studying meta-learning which plays an important role in finding optimal privacy-preserving solutions.\n Download my resumé. -- ","date":1717459200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1717459200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I received my Master\u0026rsquo;s degree in Network and Information Systems Engineering from the Faculty of Sciences, University of Porto, in 2019. I am currently pursuing a Ph.D. in Computer Science at FCUP, with a dedicated research focus on \u0026ldquo;Automated Privacy-Preserving Strategies\u0026rdquo;.","tags":null,"title":"Tânia Carvalho","type":"authors"},{"authors":["Carolina Trindade","Luís Antunes","Tânia Carvalho","Nuno Moniz"],"categories":null,"content":"","date":1717459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717459200,"objectID":"98e4cd495698ae7bf5083dd130217151","permalink":"https://tmcarvalho.github.io/publication/psd/","publishdate":"2024-06-04T00:00:00Z","relpermalink":"/publication/psd/","section":"publication","summary":"Multiple synthetic data generation models have emerged, among which deep learning models have become the vanguard due to their ability to capture the underlying characteristics of the original data. However, the resemblance of the synthetic to the original data raises important questions on the protection of individuals' privacy. As synthetic data is perceived as a means to fully protect personal information, most current related work disregards the impact of re-identification risk. In particular, limited attention has been given to exploring outliers, despite their privacy relevance. In this work, we analyze the privacy of synthetic data w.r.t the outliers. Our main findings suggest that outliers re-identification via linkage attack is feasible and easily achieved. Furthermore, additional safeguards such as differential privacy can prevent re-identification, albeit at the expense of the data utility.","tags":[],"title":"Synthetic Data Outliers: Navigating Identity Disclosure","type":"publication"},{"authors":null,"categories":null,"content":"ε-PrivateSMOTE is a technique designed for safeguarding against re-identification and linkage attacks, particularly addressing cases with a high re-identification risk. It generates synthetic data via noise-induced interpolation with differential privacy principles to obfuscate high-risk cases. ε-PrivateSMOTE allows having new cases similar to the originals while preserving privacy and maximising predictive utility. Most importanly, ε-PrivateSMOTE is a resource efficient and less time-consuming than conventional de-identification approaches such as deep learning and differential privacy-based solutions.\n","date":1705708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705708800,"objectID":"081488b03bb2ff5f5c44322cf3271ba7","permalink":"https://tmcarvalho.github.io/project/privatesmote/","publishdate":"2024-01-20T00:00:00Z","relpermalink":"/project/privatesmote/","section":"project","summary":"Differentially-Private Data Synthetisation for Efficient Re-Identification Risk Control","tags":null,"title":"ε-PrivateSMOTE","type":"project"},{"authors":["Tânia Carvalho","Nuno Moniz","Luís Antunes"],"categories":null,"content":"","date":1685577600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685577600,"objectID":"60f77dc76845b4b0fc1ab8801cb522dc","permalink":"https://tmcarvalho.github.io/publication/epia/","publishdate":"2023-06-01T00:00:00Z","relpermalink":"/publication/epia/","section":"publication","summary":"As the frontier of machine learning applications moves further into human interaction, multiple concerns arise regarding automated decision-making. Two of the most critical issues are fairness and data privacy. On the one hand, one must guarantee that automated decisions are not biased against certain groups, especially those unprotected or marginalized. On the other hand, one must ensure that the use of personal information fully abides by privacy regulations and that user identities are kept safe. The balance between privacy, fairness, and predictive performance is complex. However, despite their potential societal impact, we still demonstrate a poor understanding of the dynamics between these optimization vectors. In this paper, we study this three-way tension and how the optimization of each vector impacts others, aiming to inform the future development of safe applications. In light of claims that predictive performance and fairness can be jointly optimized, we find this is only possible at the expense of data privacy. Overall, experimental results show that one of the vectors will be penalized regardless of which of the three we optimize. Nonetheless, we find promising avenues for future work in joint optimization solutions, where smaller trade-offs are observed between the three vectors.","tags":[],"title":"A Three-Way Knot: Privacy, Fairness, and Predictive Performance Dynamics","type":"publication"},{"authors":null,"categories":null,"content":"Statistical Disclosure Control seeks to reduce the risk of confidential information disclosure by de-identifying them. Such de-identification is guaranteed through privacy-preserving techniques (PPTs). However, de-identified data usually results in loss of information, with a possible impact on data analysis precision and model predictive performance. This course covers the de-identification process which aims to protect the individual’s privacy while maintaining the interpretability of the data (i.e., its usefulness). The program includes:\n Introduction to Python Introduction to data privacy Predictive modeling Privacy-preserving techniques Training Current directions on data privacy  ","date":1682467200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682467200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://tmcarvalho.github.io/project/example/","publishdate":"2023-04-26T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"Practical course covering the basic principles of the data de-identification process.","tags":null,"title":"Hands-on data de-identification","type":"project"},{"authors":["Tânia Carvalho","Nuno Moniz","Pedro Faria","Luís Antunes"],"categories":null,"content":"","date":1677628800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677628800,"objectID":"55ac6d9e94bcbc343a610569feec387b","permalink":"https://tmcarvalho.github.io/publication/eswa/","publishdate":"2023-03-01T00:00:00Z","relpermalink":"/publication/eswa/","section":"publication","summary":"Machine learning is increasingly used in the most diverse applications and domains, whether in healthcare, to predict pathologies, or in the financial sector to detect fraud. One of the linchpins for efficiency and accuracy in machine learning is data utility. However, when it contains personal information, full access may be restricted due to laws and regulations aiming to protect individuals' privacy. Therefore, data owners must ensure that any data shared guarantees such privacy. Removal or transformation of private information (de-identification) are among the most common techniques. Intuitively, one can anticipate that reducing detail or distorting information would result in losses for model predictive performance. However, previous work concerning classification tasks using de-identified data generally demonstrates that predictive performance can be preserved in specific applications. In this paper, we aim to evaluate the existence of a trade-off between data privacy and predictive performance in classification tasks. We leverage a large set of privacy-preserving techniques and learning algorithms to provide an assessment of re-identification ability and the impact of transformed variants on predictive performance. Unlike previous literature, we confirm that the higher the level of privacy (lower re-identification risk), the higher the impact on predictive performance, pointing towards clear evidence of a trade-off.","tags":[],"title":"Towards a Data Privacy-Predictive Performance Trade-off","type":"publication"},{"authors":["Tânia Carvalho","Nuno Moniz","Pedro Faria","Luís Antunes"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"c613964539060f72b7b5ca0b841b7b61","permalink":"https://tmcarvalho.github.io/publication/survey/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/publication/survey/","section":"publication","summary":"The exponential growth of collected, processed, and shared microdata has given rise to concerns about individuals’ privacy. As a result, laws and regulations have emerged to control what organisations do with microdata and how they protect it. Statistical Disclosure Control seeks to reduce the risk of confidential information disclosure by de-identifying them. Such de-identification is guaranteed through privacy-preserving techniques (PPT). However, de-identified data usually results in loss of information, with a possible impact on data analysis precision and model predictive performance. The main goal is to protect the individual’s privacy while maintaining the interpretability of the data, i.e. its usefulness. Statistical Disclosure Control is an area that is expanding and needs to be explored since there is still no solution that guarantees optimal privacy and utility. This survey focuses on all steps of the de-identification process. We present existing PPT used in microdata de-identification, privacy measures suitable for several disclosure types and, information loss and predictive performance measures. In this survey, we discuss the main challenges raised by privacy constraints, describe the main approaches to handle these obstacles, review the taxonomies of PPT, provide a theoretical analysis of existing comparative studies, and raise multiple open issues.","tags":[],"title":"Survey on Privacy-Preserving Techniques for Data Publishing","type":"publication"},{"authors":["Tânia Carvalho","Nuno Moniz","Pedro Faria","Luís Antunes","Nitesh Chawla"],"categories":null,"content":"","date":1669852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669852800,"objectID":"875e2af20d9dc053e23efade61db1c5c","permalink":"https://tmcarvalho.github.io/publication/privatesmote/","publishdate":"2022-12-01T00:00:00Z","relpermalink":"/publication/privatesmote/","section":"publication","summary":"We can protect user data privacy via many approaches, such as statistical transformation or generative models. However, each of them has critical drawbacks. On the one hand, creating a transformed data set using conventional techniques is highly time-consuming. On the other hand, in addition to long training phases, recent deep learning-based solutions require significant computational resources. In this paper, we propose PrivateSMOTE, a technique designed for competitive effectiveness in protecting cases at maximum risk of re-identification while requiring much less time and computational resources. It works by synthetic data generation via interpolation to obfuscate high-risk cases while minimizing data utility loss of the original data. Compared to multiple conventional and state-of-the-art privacy-preservation methods on 20 data sets, PrivateSMOTE demonstrates competitive results in re-identification risk. Also, it presents similar or higher predictive performance than the baselines, including generative adversarial networks and variational autoencoders, reducing their energy consumption and time requirements by a minimum factor of 9 and 12, respectively.","tags":[],"title":"Privacy-Preserving Data Synthetisation for Secure Information Sharing","type":"publication"},{"authors":["Tânia Carvalho","Nuno Moniz","Pedro Faria","Luís Antunes"],"categories":null,"content":"","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622505600,"objectID":"ff6a19061a984819d30c916886db56ef","permalink":"https://tmcarvalho.github.io/publication/example/","publishdate":"2021-06-01T00:00:00Z","relpermalink":"/publication/example/","section":"publication","summary":"Faced with the emergence of the Covid-19 pandemic, and to better understand and contain the disease’s spread, health organisations increased the collaboration with other organisations sharing health data with data scientists and researchers. Data analysis assists such organisations in providing information that could help in decision-making processes. For this purpose, both national and regional health authorities provided health data for further processing and analysis. Shared data must comply with existing data protection and privacy regulations. Therefore, a robust de-identification procedure must be used, and a re-identification risk analysis should also be performed. De-identified data embodies state-of-the-art approaches in Data Protection by Design and Default because it requires the protection of direct and indirect identifiers (not just direct). This article highlights the importance of assessing re-identification risk before data disclosure by analysing a data set of individuals infected by Covid-19 that was made available for research purposes. We stress that it is highly important to make this data available for research purposes and that this process should be based on the state of the art methods in Data Protection by Design and by Default. Our main goal is to consider different re-identification risk analysis scenarios since the information on the intruder side is unknown. Our conclusions show that there is a risk of identity disclosure for all of the studied scenarios. For one, in particular, we proceed to an example of a re-identification attack. The outcome of such an attack reveals that it is possible to identify individuals with no much effort.","tags":[],"title":"Fundamental privacy rights in a pandemic state","type":"publication"},{"authors":["Tânia Carvalho","Nuno Moniz"],"categories":null,"content":"","date":1617235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617235200,"objectID":"db2045ab803a6b08c2facf151ea52efe","permalink":"https://tmcarvalho.github.io/publication/ida/","publishdate":"2021-04-01T00:00:00Z","relpermalink":"/publication/ida/","section":"publication","summary":"Privacy-preservation has become an essential concern in many data mining applications since the emergence of legal obligations to protect personal data. Thus, the notion of Privacy-Preserving Data Mining emerged to allow the extraction of knowledge from data without violating the privacy of individuals. Several transformation techniques have been proposed to protect the privacy of individuals. However, their application does not guarantee a null risk of an individual being re-identified. Furthermore, and most importantly, for this paper, the application of such techniques may have a considerable impact on the utility of data and their use in predictive and descriptive tasks. In this paper, we present a study to provide key insights concerning the impact of privacy-preserving techniques in predictive performance. Unlike previous work, our main conclusions point towards a noticeable impact of privacy-preservation techniques in predictive performance.","tags":[],"title":"The Compromise of Data Privacy in Predictive Performance","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://tmcarvalho.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]